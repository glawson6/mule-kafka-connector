/**
 * This file was automatically generated by the Mule Development Kit
 */
package net.taptech.kafka.mule.connector;

import net.taptech.kafka.mule.connector.config.ConnectorConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;
import org.mule.api.MuleException;
import org.mule.api.annotations.*;
import org.mule.api.annotations.lifecycle.Start;
import org.mule.api.annotations.lifecycle.Stop;
import org.mule.api.annotations.param.Optional;
import org.mule.api.callback.SourceCallback;
import org.mule.api.endpoint.EndpointException;
import org.mule.api.transport.ConnectorException;
import org.mule.config.i18n.MessageFactory;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.core.io.DefaultResourceLoader;
import org.springframework.core.io.ResourceLoader;

import java.util.Arrays;
import java.util.Collections;
import java.util.List;
import java.util.Properties;
import java.util.concurrent.*;

/**
 */
@Connector(name="kafka", friendlyName="Kafka")
public class KafkaConnector {
	private static Logger logger = LoggerFactory.getLogger(KafkaConnector.class);
	
	@Config
	ConnectorConfig config;

	private Properties consumerProperties = new Properties();
	private Properties producerProperties = new Properties();
	private ExecutorService producerPool;
	private ExecutorService consumerPool;
	private static int connectorCount = 0;
	private ResourceLoader resourceLoader = new DefaultResourceLoader();

	private static final int DEFAULT_POOL_SIZE = 5;
	
	@Start
	public void initialize() throws Exception{
		logger.info("KafkaConnector initialize called with count "+ ++connectorCount);
		consumerProperties.load(resourceLoader.getResource(config.getConsumerPropertiesFile()).getInputStream());
		producerProperties.load(resourceLoader.getResource(config.getProducerPropertiesFile()).getInputStream());
		int producerThreads = determineThreads(producerProperties.getProperty(KafkaConnectorConstants.PRODUCER_THREADS));
		int consumerThreads = determineThreads(consumerProperties.getProperty(KafkaConnectorConstants.CONSUMER_THREADS));
		producerPool = Executors.newFixedThreadPool(producerThreads);
		consumerPool = Executors.newFixedThreadPool(consumerThreads);
	}

	private int determineThreads(String property) {

		int threads = DEFAULT_POOL_SIZE;
		if (null != property){
			try{
				 threads = Integer.valueOf(property);
			} catch( NumberFormatException nfe){
				StringBuilder sb = new StringBuilder("Error converting ");
				sb.append(property);
				sb.append("to int value: ");
				sb.append(nfe.getMessage());
				sb.append(" Using default value of ").append(DEFAULT_POOL_SIZE);
				sb.append(" for pool size.");
				logger.warn(sb.toString());
			}
		}
		return threads;
	}

	public Properties getConsumerProperties() {
		return consumerProperties;
	}

	public Properties getProducerProperties() {
		return producerProperties;
	}

	public ExecutorService getProducerPool() {
		return producerPool;
	}

	public ExecutorService getConsumerPool() {
		return consumerPool;
	}

	@Stop
	public void shutdownAndAwaitTermination() {
		ExecutorService [] servicesArray = {getProducerPool(), getConsumerPool()};
		for (ExecutorService pool: Arrays.asList(servicesArray)){
			pool.shutdown(); // Disable new tasks from being submitted
			try {
				// Wait a while for existing tasks to terminate
				if (!pool.awaitTermination(60, TimeUnit.SECONDS)) {
					pool.shutdownNow(); // Cancel currently executing tasks
					// Wait a while for tasks to respond to being cancelled
					if (!pool.awaitTermination(60, TimeUnit.SECONDS))
						System.err.println("Pool did not terminate");
				}
			} catch (InterruptedException ie) {
				// (Re-)Cancel if current thread also interrupted
				pool.shutdownNow();
				// Preserve interrupt status
				Thread.currentThread().interrupt();
			}
		}
	}

	public ConnectorConfig getConfig() {
		return config;
	}
	public void setConfig(ConnectorConfig config) {
		this.config = config;
	}

	public static final Integer ONE = 1;

	public static final Integer DEFAULT_DELAY = 1000;

	@Source(name = "Consumer", friendlyName = "Consumer")
	public void consumer(SourceCallback callback, @Optional String topic, String propertyFileOverrides) {
		logger.info("Creating simpleConsumer with propertyFileOverrides {}",propertyFileOverrides);
		Integer delay = DEFAULT_DELAY;
		String [] topicsArray = consumerProperties.getProperty(KafkaConnectorConstants.CONSUMER_TOPICS).split(",");
		Properties properties = getConsumerProperties();
		if (null != topic){
			properties.put(KafkaConnectorConstants.CONSUMER_TOPICS, topic);
		}
		KafkaConsumerRunner runner = new KafkaConsumerRunner(properties, callback);
		logger.debug("Subscribing to topics {} with properties",topicsArray,properties);
		consumerPool.submit(runner);
	}
	
	@Processor(name = "Producer", friendlyName = "Producer")
	public List<RecordMetadata> producer(@Optional String topic, String key, String message, @Optional String propertyFileOverrides) throws ExecutionException, InterruptedException, EndpointException {
		Properties properties = getProducerProperties();
		if (null == topic){
			topic = properties.getProperty(KafkaConnectorConstants.PRODUCER_TOPIC);
		}
		if (null == topic){
			throw new EndpointException(MessageFactory.createStaticMessage("Topic cannot be null. Either pass in producer XMl or put 'producer.topic' in configuration file'"));
		}
		ProducerRecord producerRecord = new ProducerRecord(topic, key, message);
		logger.debug("Using producer record {} with properties {}",producerRecord,properties);
		List<ProducerRecord> producerRecords = Collections.singletonList(producerRecord);
		KafkaProducerRunner runner = new KafkaProducerRunner(properties, producerRecords);
		Future<List<RecordMetadata>> results = producerPool.submit(runner);
		return results.get();
	}

	public void shutdown() {
		ExecutorService executor = getProducerPool();
		if (executor != null) {
			executor.shutdown();
		}

		try {
			if (!executor.awaitTermination(Integer.MAX_VALUE,
					TimeUnit.MILLISECONDS)) {
				logger.warn("Threadpool did not terminate cleanly.");
			}
		} catch (Exception e) {
			logger.error("Threadpool did not terminate cleanly:", e);
		}

		logger.info("all threads terminated");
		/*
		if (connector != null) {
			connector.shutdown();
		}
		*/
		logger.info("consumer group shutdown");
	}

}
